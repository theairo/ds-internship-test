{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1813a4b",
   "metadata": {},
   "source": [
    "# Dataset creation notebook\n",
    "\n",
    "Purpose: create a dataset for NER model using Gemini API for batched based sample generation\n",
    "\n",
    "Structure:\n",
    "1. Setup & Configuration\n",
    "3. Bio tags assignment\n",
    "4. Generating and saving the whole dataset\n",
    "\n",
    "### Todo (future improvements)\n",
    "1. Problem - duplicated samples! Warning: data leak during training\n",
    "1. Implement checkpoint saves for dataset creation (in case of error)\n",
    "2. Tagging validation\n",
    "3. Docstrings to essential functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4739bc9",
   "metadata": {},
   "source": [
    "### Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f6d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from getpass import getpass\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b185c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_POSITIVE = \"\"\"\n",
    "Generate 20 unique items in valid JSON Lines format. \n",
    "Output **only** JSON objects, one per line, with no additional commentary, explanation, or text. \n",
    "Each line must be a dictionary with keys:\n",
    "\"text\" — a sentence containing one or more specific mountain names\n",
    "\"entities\" — a list of all mountain names mentioned in the sentence, including alternative names\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_NEGATIVE = \"\"\"\n",
    "Generate 20 unique items in valid JSON Lines format. \n",
    "Output **only** JSON objects, one per line, with no commentary.\n",
    "Each line must be a dictionary with:\n",
    "\"text\" — a sentence about geography, hiking, or nature\n",
    "\"entities\" — an empty list []\n",
    "Use generic terms such as \"hill\", \"ridge\", \"peak\", \"valley\", \"cliff\" and include real geographic names that are NOT mountains, like rivers, lakes, deserts, islands, or regions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51c2c57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_api():\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    if not api_key:\n",
    "        api_key = getpass(\"Enter Gemini API Key: \")\n",
    "\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    return client\n",
    "\n",
    "# Maximum number of times to retry a failed API call before giving up on that specific request\n",
    "MAX_RETRIES = 5\n",
    "\n",
    "def generate_batch_data(client, prompt, batch_count=1):\n",
    "    dataset = []\n",
    "\n",
    "    # Tqdm wrapper makes a progress bar\n",
    "    for i in tqdm(range(batch_count), desc=\"Generating batches\"):\n",
    "        try:\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    response = client.models.generate_content(\n",
    "                        model=\"gemini-2.5-flash\",\n",
    "                        contents=prompt,\n",
    "                        config=types.GenerateContentConfig(\n",
    "                            temperature=0.8,\n",
    "                            response_mime_type=\"application/json\"\n",
    "                        )\n",
    "                    )\n",
    "                    break # success\n",
    "                except Exception as e:\n",
    "                    # Exponential backoff (base 10)\n",
    "                    print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "                    wait_time = 10 * (attempt + 1) \n",
    "                    print(f\"Retrying in {wait_time}s …\")\n",
    "                    time.sleep(wait_time)\n",
    "\n",
    "            # Extract the raw generated text\n",
    "            raw_text = response.candidates[0].content.parts[0].text\n",
    "\n",
    "            # Split by lines (JSONL format) and parse\n",
    "            batch_data = [json.loads(line) for line in raw_text.strip().splitlines() if line.strip()]\n",
    "\n",
    "            # Add to overall dataset\n",
    "            dataset.extend(batch_data)\n",
    "            \n",
    "            time.sleep(5)  # rate limit pause\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on batch {i}: {e}. Retrying after 10s …\")\n",
    "            time.sleep(10)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a653add",
   "metadata": {},
   "source": [
    "### Verify setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61120ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating batches: 100%|██████████| 1/1 [00:15<00:00, 15.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples returned: 20\n",
      "Preview of first 2 samples sample:\n",
      "[{'text': 'Climbing Mount Everest, also known as Sagarmatha in Nepal and Chomolungma in Tibet, is a lifelong dream for many alpinists.', 'entities': ['Mount Everest', 'Sagarmatha', 'Chomolungma']}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client = setup_api()\n",
    "    test_response = generate_batch_data(client, PROMPT_POSITIVE, 1)\n",
    "    print(f\"Total samples returned: {len(test_response)}\")\n",
    "    print(\"Preview of first 2 samples sample:\")\n",
    "    print(test_response[:1])\n",
    "except Exception as e:\n",
    "    print(f\"Smoke test failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57537067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def assign_bio_tags(entry):\n",
    "    \"\"\"\n",
    "        Converts entity lists to BIO tags.\n",
    "    \"\"\"\n",
    "    text = entry['text']\n",
    "    \n",
    "    # Robust regex tokenization\n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "    tags = [\"O\"] * len(tokens)\n",
    "    \n",
    "    entities = entry.get('entities', [])\n",
    "    \n",
    "    for entity in entities:\n",
    "        # Tokenize the entity string using the exact same regex\n",
    "        entity_tokens = re.findall(r'\\w+|[^\\w\\s]', entity)\n",
    "        entity_len = len(entity_tokens)\n",
    "        \n",
    "        # Sliding window match\n",
    "        for i in range(len(tokens) - entity_len + 1):\n",
    "            if tokens[i:i+entity_len] == entity_tokens:\n",
    "                tags[i] = \"B-MNT\"\n",
    "                for j in range(1, entity_len):\n",
    "                    tags[i+j] = \"I-MNT\"\n",
    "    \n",
    "    return {\"tokens\": tokens, \"ner_tags\": tags}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5272a54",
   "metadata": {},
   "source": [
    "### Bio-tags assignment test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123f5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 1:\n",
      "{\n",
      "    \"tokens\": [\n",
      "        \"The\",\n",
      "        \"climb\",\n",
      "        \"to\",\n",
      "        \"Mount\",\n",
      "        \"Fitz\",\n",
      "        \"Roy\",\n",
      "        \"was\",\n",
      "        \"difficult\",\n",
      "        \"near\",\n",
      "        \"K2\",\n",
      "        \"!\"\n",
      "    ],\n",
      "    \"ner_tags\": [\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"B-MNT\",\n",
      "        \"I-MNT\",\n",
      "        \"I-MNT\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"B-MNT\",\n",
      "        \"O\"\n",
      "    ]\n",
      "}\n",
      "\n",
      "Test 2:\n",
      "{\n",
      "    \"tokens\": [\n",
      "        \"The\",\n",
      "        \"river\",\n",
      "        \"flows\",\n",
      "        \"near\",\n",
      "        \"the\",\n",
      "        \"high\",\n",
      "        \"ridge\",\n",
      "        \",\",\n",
      "        \"far\",\n",
      "        \"from\",\n",
      "        \"the\",\n",
      "        \"city\",\n",
      "        \"center\",\n",
      "        \".\"\n",
      "    ],\n",
      "    \"ner_tags\": [\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\",\n",
      "        \"O\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: Positive Sample\n",
    "test_data_1 = {\n",
    "    \"text\": \"The climb to Mount Fitz Roy was difficult near K2!\",\n",
    "    \"entities\": [\"Mount Fitz Roy\", \"K2\"]\n",
    "}\n",
    "\n",
    "# Test Case 2: Negative Sample\n",
    "test_data_2 = {\n",
    "    \"text\": \"The river flows near the high ridge, far from the city center.\",\n",
    "    \"entities\": []\n",
    "}\n",
    "\n",
    "# --- Execute Tests ---\n",
    "print(\"\\nTest 1:\")\n",
    "result_1 = assign_bio_tags(test_data_1)\n",
    "print(json.dumps(result_1, indent=4))\n",
    "\n",
    "print(\"\\nTest 2:\")\n",
    "result_2 = assign_bio_tags(test_data_2)\n",
    "print(json.dumps(result_2, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4f7ba",
   "metadata": {},
   "source": [
    "# Generating a whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ae98d3",
   "metadata": {},
   "source": [
    "### Save & Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2ecc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(data, filename):\n",
    "    \"\"\"\n",
    "        Save jsonl data to file \n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for entry in data:\n",
    "            json.dump(entry, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "def load_jsonl(filename):\n",
    "    \"\"\"\n",
    "        Load jsonl data from file\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip():  # avoid empty lines\n",
    "                data.append(json.loads(line))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45439df0",
   "metadata": {},
   "source": [
    "### Caution: This section generates data using an external API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ef978c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Positive Samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating batches:  83%|████████▎ | 5/6 [01:27<00:19, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n",
      "Retrying in 10s …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating batches: 100%|██████████| 6/6 [01:54<00:00, 19.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Negative Samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating batches: 100%|██████████| 6/6 [01:08<00:00, 11.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generate raw data\n",
    "\n",
    "# One batch contains 20 samples\n",
    "POSITIVE_BATCH_COUNT = 6 \n",
    "NEGATIVE_BATCH_COUNT = 6\n",
    "\n",
    "try:\n",
    "    client = setup_api()\n",
    "\n",
    "    print(\"\\nGenerating Positive Samples...\")\n",
    "    pos_data = generate_batch_data(client, PROMPT_POSITIVE, batch_count=POSITIVE_BATCH_COUNT)\n",
    "    save_jsonl(pos_data, \"data/raw/raw_positive.jsonl\")\n",
    "\n",
    "    print(\"\\nGenerating Negative Samples...\")\n",
    "    neg_data = generate_batch_data(client, PROMPT_NEGATIVE, batch_count=NEGATIVE_BATCH_COUNT)\n",
    "    save_jsonl(neg_data, \"data/raw/raw_negative.jsonl\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAPI generation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd283fbc",
   "metadata": {},
   "source": [
    "### Processing and Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ba3f562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Raw Sample Count: 240\n",
      "Unique Raw Sample Count: 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying BIO Tags: 100%|██████████| 236/236 [00:00<00:00, 78622.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagging complete. Total samples: 236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load raw data from disk\n",
    "raw_data = load_jsonl(\"data/raw/raw_positive.jsonl\") + load_jsonl(\"data/raw/raw_negative.jsonl\")\n",
    "random.shuffle(raw_data)\n",
    "\n",
    "# DEDUPPLICATION\n",
    "print(f\"Original Raw Sample Count: {len(raw_data)}\")\n",
    "\n",
    "unique_data = []\n",
    "processed_texts = set()\n",
    "\n",
    "for sample in raw_data:\n",
    "    text = sample.get('text') \n",
    "    \n",
    "    if text and text not in processed_texts:\n",
    "        processed_texts.add(text)\n",
    "        unique_data.append(sample)\n",
    "\n",
    "raw_data = unique_data # Overwrite the raw_data list with unique samples\n",
    "\n",
    "print(f\"Unique Raw Sample Count: {len(raw_data)}\")\n",
    "\n",
    "processed_dataset = []\n",
    "for entry in tqdm(raw_data, desc=\"Applying BIO Tags\"):\n",
    "    try:\n",
    "        tagged_entry = assign_bio_tags(entry)\n",
    "        processed_dataset.append(tagged_entry)\n",
    "        \n",
    "        # Todo: write validation of bio tags\n",
    "        #\n",
    "        # if validate_bio_tags(tagged_entry):\n",
    "        #     processed_dataset.append(tagged_entry)\n",
    "        # else:\n",
    "        #     print(f\"Skipping invalid entry: {entry['text']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Tagging failed for an entry: {e}\")\n",
    "        continue \n",
    "        \n",
    "print(f\"Tagging complete. Total samples: {len(processed_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166b577",
   "metadata": {},
   "source": [
    "### Split and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82deb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SPLIT AND FINAL EXPORT\n",
    "train_data, remain_data = train_test_split(processed_dataset, test_size=0.4, random_state=42)\n",
    "val_data, test_data = train_test_split(remain_data, test_size=0.5, random_state=42)\n",
    "\n",
    "save_jsonl(train_data, \"data/final/train.jsonl\")\n",
    "save_jsonl(val_data, \"data/final/validation.jsonl\")\n",
    "save_jsonl(test_data, \"data/final/test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a68e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
